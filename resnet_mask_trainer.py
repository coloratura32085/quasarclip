# resnet_mask_trainer.py (å®Œæ•´ç‰ˆæœ¬)

import argparse
import os
import torch
import pytorch_lightning as pl
from datasets import load_from_disk
from torch.utils.data import DataLoader
from datetime import datetime

from dataset_util.PairDataset import PairDataset
from imageutil.trans import CustomSmartCrop
from models.masked_autoencoder import MaskedAutoEncoder
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint
from pytorch_lightning import loggers as pl_loggers
from root_path import ROOT_PATH
import torchvision.transforms as transforms

# å¯¼å…¥ wandb
import wandb
from pytorch_lightning.loggers import WandbLogger

# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# è®¾ç½®éšæœºç§å­
pl.seed_everything(42)


class FlattenAndReshape:
    """å°†å›¾åƒå±•å¹³åé‡æ–°æ•´å½¢"""

    def __init__(self, size):
        self.size = size

    def __call__(self, x):
        x_flat = x.flatten()
        x_reshaped = x_flat.view(self.size, self.size, 5)
        x_final = x_reshaped.permute(2, 0, 1)
        return x_final


def parse_args():
    parser = argparse.ArgumentParser(description="Masked AutoEncoder Training Script")

    # è£å‰ªå’Œæ©ç å‚æ•°
    parser.add_argument('--crop_size', type=int, default=32,
                        help="Crop size for transforms (default: 32)")
    parser.add_argument('--core_size', type=int, default=10,
                        help="Size of quasar core region that must be included (default: 10)")
    parser.add_argument('--mask_ratio', type=float, default=0.75,
                        help="Ratio of pixels to mask (default: 0.75)")

    # æ•°æ®è·¯å¾„
    parser.add_argument('--train_data_path', type=str,
                        default=f'../data/data_g3_z/train_dataset',
                        help="Path to the training dataset")
    parser.add_argument('--test_data_path', type=str,
                        default=f'../data/data_g3_z/test_dataset',
                        help="Path to the test dataset")

    # æ¨¡å‹å‚æ•°
    parser.add_argument('--in_channels', type=int, default=5,
                        help="Number of input channels (default: 5)")
    parser.add_argument('--base_channels', type=int, default=64,
                        help="Base number of channels in ResNet (default: 64)")

    # ä¼˜åŒ–å™¨è¶…å‚æ•°
    parser.add_argument('--lr', type=float, default=1e-3,
                        help="Learning rate (default: 1e-3)")
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                        help="Weight decay (default: 1e-4)")

    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=128,
                        help="Batch size (default: 128)")
    parser.add_argument('--max_epochs', type=int, default=100,
                        help="Number of epochs (default: 100)")
    parser.add_argument('--limit_val_batches', type=int, default=100,
                        help="Limit validation batches (default: 100)")
    parser.add_argument('--gradient_clip_val', type=float, default=1.0,
                        help="Gradient clipping value (default: 1.0)")
    parser.add_argument('--num_workers', type=int, default=4,
                        help="Number of data loading workers (default: 4)")

    # è¾“å‡ºè·¯å¾„
    parser.add_argument('--output_dir', type=str,
                        default=f'{ROOT_PATH}/outputs/mae',
                        help="Root output directory for checkpoints and logs")

    # wandb å‚æ•°
    parser.add_argument('--wandb_project', type=str, default='astro-mae',
                        help="W&B project name")
    parser.add_argument('--wandb_name', type=str, default=None,
                        help="W&B run name")
    parser.add_argument('--wandb_offline', action='store_true',
                        help="Run W&B in offline mode")

    # GPU è®¾ç½®
    parser.add_argument('--devices', type=int, nargs='+', default=[0],
                        help="GPU device IDs (default: [0])")

    return parser.parse_args()


class MAELightning(pl.LightningModule):
    """
    PyTorch Lightning æ¨¡å—ï¼šå°è£…æ©ç è‡ªç¼–ç å™¨è®­ç»ƒé€»è¾‘
    """

    def __init__(self, in_channels=5, base_channels=64, lr=1e-3,
                 weight_decay=1e-4, mask_ratio=0.75):
        super(MAELightning, self).__init__()
        self.save_hyperparameters()

        # åˆå§‹åŒ–æ¨¡å‹
        self.model = MaskedAutoEncoder(in_channels=in_channels,
                                       base_channels=base_channels)

        # æŸå¤±å‡½æ•°
        self.criterion = torch.nn.MSELoss()

        # ä¿å­˜ mask_ratio
        self.mask_ratio = mask_ratio

    def generate_mask(self, images):
        """
        åŠ¨æ€ç”Ÿæˆéšæœºæ©ç 
        Args:
            images: (B, C, H, W)
        Returns:
            mask: (B, C, H, W), 1=é®ç›–ï¼Œ0=ä¿ç•™
        """
        B, C, H, W = images.shape
        # ä¸ºæ¯å¼ å›¾åƒç”Ÿæˆä¸åŒçš„æ©ç 
        mask = torch.rand(B, 1, H, W, device=images.device) < self.mask_ratio
        mask = mask.expand(-1, C, -1, -1).float()
        return mask

    def forward(self, x, mask=None):
        return self.model(x, mask)

    def training_step(self, batch, batch_idx):
        images = batch['image']

        # åŠ¨æ€ç”Ÿæˆæ©ç 
        mask = self.generate_mask(images)

        # å‰å‘ä¼ æ’­
        reconstructed = self(images, mask)

        # åªåœ¨æ©ç åŒºåŸŸè®¡ç®—æŸå¤±ï¼ˆè¢«é®ç›–çš„éƒ¨åˆ†ï¼‰
        loss_masked = self.criterion(reconstructed * mask, images * mask)

        # åŒæ—¶ç›‘æ§å…¨å›¾é‡æ„æŸå¤±ï¼ˆç”¨äºåˆ†æï¼‰
        loss_full = self.criterion(reconstructed, images)

        # è®¡ç®—æœªè¢«æ©ç åŒºåŸŸçš„æŸå¤±ï¼ˆå¯è§éƒ¨åˆ†ï¼‰
        loss_visible = self.criterion(reconstructed * (1 - mask), images * (1 - mask))

        # è®°å½•æ—¥å¿—
        self.log('train_loss_masked', loss_masked, on_step=True, on_epoch=True,
                 prog_bar=True, sync_dist=True)
        self.log('train_loss_full', loss_full, on_step=False, on_epoch=True,
                 sync_dist=True)
        self.log('train_loss_visible', loss_visible, on_step=False, on_epoch=True,
                 sync_dist=True)

        return loss_masked

    def validation_step(self, batch, batch_idx):
        images = batch['image']

        # ç”Ÿæˆæ©ç 
        mask = self.generate_mask(images)

        # å‰å‘ä¼ æ’­
        reconstructed = self(images, mask)

        # è®¡ç®—å„ç§æŸå¤±
        loss_masked = self.criterion(reconstructed * mask, images * mask)
        loss_full = self.criterion(reconstructed, images)
        loss_visible = self.criterion(reconstructed * (1 - mask), images * (1 - mask))

        # è®°å½•æ—¥å¿—
        self.log('val_loss_masked', loss_masked, on_epoch=True, prog_bar=True,
                 sync_dist=True)
        self.log('val_loss_full', loss_full, on_epoch=True, sync_dist=True)
        self.log('val_loss_visible', loss_visible, on_epoch=True, sync_dist=True)

        return loss_masked

    def configure_optimizers(self):
        """é…ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.hparams.lr,
            weight_decay=self.hparams.weight_decay
        )

        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=self.trainer.max_epochs,
            eta_min=self.hparams.lr / 100
        )

        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'interval': 'epoch',
                'frequency': 1
            }
        }


def main():
    args = parse_args()

    # ç”Ÿæˆå”¯ä¸€å®éªŒè·¯å¾„
    current_time = datetime.now().strftime("%m%d_%H%M")

    if args.wandb_name:
        run_name = f"{args.wandb_name}_{current_time}"
    else:
        run_name = f"mae_crop{args.crop_size}_core{args.core_size}_mask{int(args.mask_ratio * 100)}_lr{args.lr}_{current_time}"

    print("=" * 70)
    print(f"ğŸš€ Starting Experiment: {run_name}")
    print("=" * 70)
    print(f"ğŸ“Š Configuration:")
    print(f"  - Crop Size: {args.crop_size}x{args.crop_size}")
    print(f"  - Core Size: {args.core_size}x{args.core_size}")
    print(f"  - Mask Ratio: {args.mask_ratio}")
    print(f"  - Batch Size: {args.batch_size}")
    print(f"  - Learning Rate: {args.lr}")
    print(f"  - Max Epochs: {args.max_epochs}")
    print(f"  - Devices: {args.devices}")
    print("=" * 70)

    experiment_dir = os.path.join(args.output_dir, run_name)
    os.makedirs(experiment_dir, exist_ok=True)
    print(f"ğŸ“ Experiment Directory: {experiment_dir}\n")

    # åŠ è½½æ•°æ®é›†
    print("ğŸ“¦ Loading datasets...")
    train_dataset_hf = load_from_disk(args.train_data_path)
    test_dataset_hf = load_from_disk(args.test_data_path)
    print(f"  - Train dataset size: {len(train_dataset_hf)}")
    print(f"  - Test dataset size: {len(test_dataset_hf)}")

    # å®šä¹‰ transform
    transform = transforms.Compose([
        CustomSmartCrop(crop_size=args.crop_size, core_size=args.core_size),
        FlattenAndReshape(size=args.crop_size),
    ])

    # åˆ›å»ºæ•°æ®é›†
    train_dataset = PairDataset(train_dataset_hf, transform=transform)
    test_dataset = PairDataset(test_dataset_hf, transform=transform)

    # åˆ›å»º DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True if args.num_workers > 0 else False
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True if args.num_workers > 0 else False
    )

    print(f"  - Train batches: {len(train_loader)}")
    print(f"  - Test batches: {len(test_loader)}\n")

    # åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ¤– Initializing model...")
    model = MAELightning(
        in_channels=args.in_channels,
        base_channels=args.base_channels,
        lr=args.lr,
        weight_decay=args.weight_decay,
        mask_ratio=args.mask_ratio
    )

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  - Total parameters: {total_params:,}")
    print(f"  - Trainable parameters: {trainable_params:,}\n")

    # åˆå§‹åŒ– WandbLogger
    print("ğŸ“Š Initializing Wandb Logger...")
    wandb_logger = WandbLogger(
        project=args.wandb_project,
        name=run_name,
        offline=args.wandb_offline,
        log_model=True,
        save_dir=experiment_dir,
        version=run_name
    )

    wandb_logger.log_hyperparams({
        "architecture": "Masked-AutoEncoder-ResNet",
        "dataset": "astro-g3",
        "crop_size": args.crop_size,
        "core_size": args.core_size,
        "mask_ratio": args.mask_ratio,
        "in_channels": args.in_channels,
        "base_channels": args.base_channels,
        "experiment_dir": experiment_dir
    })

    # è®¾ç½®è®­ç»ƒå™¨
    trainer = pl.Trainer(
        log_every_n_steps=16,
        default_root_dir=experiment_dir,
        enable_checkpointing=True,
        gradient_clip_val=args.gradient_clip_val,
        max_epochs=args.max_epochs,
        limit_val_batches=args.limit_val_batches,
        logger=wandb_logger,
        callbacks=[
            LearningRateMonitor(logging_interval='step'),
            ModelCheckpoint(
                dirpath=os.path.join(experiment_dir, "checkpoints"),
                monitor="val_loss_masked",
                save_top_k=3,
                save_last=True,
                every_n_epochs=1,
                mode="min",
                filename='epoch_{epoch:03d}-val_loss_masked_{val_loss_masked:.4f}',
                auto_insert_metric_name=False
            ),
        ],
        strategy='ddp' if len(args.devices) > 1 else 'auto',
        accelerator='gpu',
        devices=args.devices,
        precision='16-mixed',
        enable_progress_bar=True,
        enable_model_summary=True
    )

    # è®­ç»ƒ
    print("\n" + "=" * 70)
    print("ğŸ¯ Starting training...")
    print("=" * 70 + "\n")

    trainer.fit(model, train_loader, test_loader)

    print("\n" + "=" * 70)
    print("âœ… Training completed!")
    print(f"ğŸ“ Best model saved at: {trainer.checkpoint_callback.best_model_path}")
    print(f"ğŸ“ˆ Best validation loss (masked): {trainer.checkpoint_callback.best_model_score:.6f}")
    print("=" * 70)

    wandb.finish()


if __name__ == '__main__':
    main()
