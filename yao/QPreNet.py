# å¯¼å…¥ wandb
import wandb
from pytorch_lightning.loggers import WandbLogger
import argparse
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl
from datasets import load_from_disk
from torch.utils.data import DataLoader, Dataset
from datetime import datetime
import numpy as np
import math
# è®¾ç½® Wandb API Key
# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

from dataset_util.PairDataset import PairDataset
from root_path import ROOT_PATH
from specutil.scheduler import CosineAnnealingWithWarmupLR

load_dotenv()


class IfeNet(nn.Module):
    """
    è®ºæ–‡ Figure 3 çš„å¤ç°:
    è¾“å…¥: 64x64x5 (SDSS Images)
    è¾“å‡º: 32ç»´ç‰¹å¾å‘é‡
    """

    def __init__(self, input_channels=5):
        super().__init__()

        # Conv1: 64x64 -> 30x30 (Paper Table 1: k=5, s=1 -> pool k=2)
        # (64-5+1)/1 = 60 -> Pool(2) -> 30
        self.conv1 = nn.Sequential(
            nn.Conv2d(input_channels, 16, kernel_size=5, stride=1, padding=0),
            nn.ReLU(),  # Paper mentions CBAM, substituting with ReLU for base implementation
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

        # Conv2: 30x30 -> 14x14 (Paper Table 1: k=3, s=1 -> pool k=2)
        # (30-3+1)/1 = 28 -> Pool(2) -> 14
        self.conv2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

        # Conv3: 14x14 -> 6x6 (Paper Table 1: k=3, s=1 -> pool k=2)
        # (14-3+1)/1 = 12 -> Pool(2) -> 6
        self.conv3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

        # Flatten size calculation: 6 * 6 * 64 = 2304

        # Fully Connected Layers: 2304 -> 1028 -> 32
        self.fc = nn.Sequential(
            nn.Linear(2304, 1028),
            nn.Tanh(),  # è®ºæ–‡ Figure 5 çš„ Hidden Layers ç”¨äº† Tanhï¼Œè¿™é‡Œ FC ä¹Ÿä¿æŒä¸€è‡´æˆ–ç”¨ ReLU
            nn.Dropout(0.5),  # è®ºæ–‡ Figure 3 åŒ…å« Dropout
            nn.Linear(1028, 32)
        )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = x.view(x.size(0), -1)  # Flatten
        x = self.fc(x)
        return x


class RegNetZ(nn.Module):
    """
    è®ºæ–‡ Figure 5 çš„å¤ç°: Mixture Density Network (MDN)
    è¾“å…¥: èåˆç‰¹å¾ (Image 32 + Params 15 = 47)
    è¾“å‡º: 5ä¸ªé«˜æ–¯åˆ†å¸ƒçš„ å‚æ•° (mu, sigma, omega)
    """

    def __init__(self, input_dim, num_gaussians=5):
        super().__init__()
        self.num_gaussians = num_gaussians

        # Hidden Layers: Input -> 50 -> 100
        self.hidden1 = nn.Linear(input_dim, 50)
        self.hidden2 = nn.Linear(50, 100)

        # Output Layer: 100 -> 3 * num_gaussians (mu, sigma, omega)
        self.output_layer = nn.Linear(100, num_gaussians * 3)

    def forward(self, x):
        # Activation function: Tanh (Paper Figure 5)
        x = torch.tanh(self.hidden1(x))
        x = torch.tanh(self.hidden2(x))

        output = self.output_layer(x)

        # Split output into parameters [cite: 187, 188, 190]
        mu = output[:, :self.num_gaussians]
        sigma = output[:, self.num_gaussians:2 * self.num_gaussians]
        omega = output[:, 2 * self.num_gaussians:]

        # Constraints:
        # Sigma must be positive: exp(sigma)
        sigma = torch.exp(sigma)

        # Omega must sum to 1: Softmax(omega) [cite: 188]
        omega = F.softmax(omega, dim=1)

        return mu, sigma, omega


class QPreNet(pl.LightningModule):
    def __init__(self, lr=1e-3, weight_decay=1e-4, T_max=10000, T_warmup=1000):
        super().__init__()
        self.save_hyperparameters()

        # 1. å›¾åƒç‰¹å¾æå– (Input: 5 channels)
        self.ife_net = IfeNet(input_channels=5)

        # 2. èåˆç‰¹å¾é•¿åº¦
        # Image Features (32) + Photometric Data (15)
        self.fused_dim = 32 + 15

        # 3. å›å½’ç½‘ç»œ (MDN)
        self.reg_net = RegNetZ(input_dim=self.fused_dim, num_gaussians=5)

    def forward(self, img, params):
        # æå–å›¾åƒç‰¹å¾
        img_feat = self.ife_net(img)  # [Batch, 32]

        # èåˆç‰¹å¾ [cite: 19] "concatenated to form fused features"
        # ç¡®ä¿ params æ˜¯ float32
        params = params.float()
        fused = torch.cat([img_feat, params], dim=1)  # [Batch, 47]

        # é¢„æµ‹ MDN å‚æ•°
        mu, sigma, omega = self.reg_net(fused)
        return mu, sigma, omega

    def mdn_loss(self, target, mu, sigma, omega):
        """
        è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤± (Negative Log Likelihood)
        Target: çœŸå®çº¢ç§» z
        """
        target = target.unsqueeze(1).expand_as(mu)

        # è®¡ç®—é«˜æ–¯æ¦‚ç‡å¯†åº¦ N(y | mu, sigma) çš„ Log å€¼
        # log( 1/sqrt(2pi*sigma^2) * exp(...) )
        # = -0.5*log(2pi) - log(sigma) - 0.5*((y-mu)/sigma)^2
        log_gaussian = -0.5 * math.log(2 * math.pi) - torch.log(sigma) - 0.5 * ((target - mu) / sigma) ** 2

        # è®¡ç®—åŠ æƒ Log æ¦‚ç‡: log(omega) + log_gaussian
        log_prob = torch.log(omega) + log_gaussian

        # LogSumExp æŠ€å·§è®¡ç®—æ€»æ¦‚ç‡çš„ Log: log( sum(exp(log_prob)) )
        log_likelihood = torch.logsumexp(log_prob, dim=1)

        # Loss = -Mean(LogLikelihood)
        return -torch.mean(log_likelihood)

    def training_step(self, batch, batch_idx):
        # ä» batch å­—å…¸ä¸­è§£åŒ…æ•°æ®
        img = batch['image']
        params = batch['probs']
        z = batch['z']

        mu, sigma, omega = self(img, params)
        loss = self.mdn_loss(z, mu, sigma, omega)

        self.log('train_loss', loss, on_epoch=True, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        img = batch['image']
        params = batch['probs']
        z = batch['z']

        mu, sigma, omega = self(img, params)
        loss = self.mdn_loss(z, mu, sigma, omega)

        # è®¡ç®—é¢„æµ‹å€¼ï¼šé«˜æ–¯æ··åˆæ¨¡å‹çš„å‡å€¼ [cite: 196]
        # Photo-z = sum(omega * mu)
        pred_z = torch.sum(omega * mu, dim=1)

        # è®¡ç®— MAE æ–¹ä¾¿è§‚å¯Ÿ
        mae = F.l1_loss(pred_z, z)

        # =============================================================
        # [æ–°å¢] ç»Ÿè®¡ Delta z < 0.1 å’Œ < 0.15 çš„æ¯”ä¾‹
        # =============================================================
        # æ ¹æ®è®ºæ–‡å…¬å¼ï¼š|Delta z| = |z_spec - z_photo| / (1 + z_spec) [cite: 22, 244]

        # 1. è®¡ç®—å½’ä¸€åŒ–è¯¯å·®
        # æ³¨æ„ï¼šåˆ†æ¯æ˜¯ (1 + z_spec)ï¼Œå³ (1 + z)
        normalized_error = torch.abs(z - pred_z) / (1 + z)

        # 2. ç»Ÿè®¡æ¯”ä¾‹ (Accuracy)
        # å°†å¸ƒå°” tensor è½¬æ¢ä¸º float (True->1.0, False->0.0) ç„¶åæ±‚å‡å€¼
        acc_0_1 = (normalized_error < 0.1).float().mean()
        acc_0_15 = (normalized_error < 0.15).float().mean()

        # 3. è®°å½•æ—¥å¿— (prog_bar=True ä¼šåœ¨è®­ç»ƒè¿›åº¦æ¡ç›´æ¥æ˜¾ç¤º)
        self.log('val_loss', loss, on_epoch=True, prog_bar=True)
        self.log('val_mae', mae, on_epoch=True, prog_bar=True)
        self.log('val_acc_0.1', acc_0_1, on_epoch=True, prog_bar=True)
        self.log('val_acc_0.15', acc_0_15, on_epoch=True, prog_bar=True)

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.hparams.lr,
            weight_decay=self.hparams.weight_decay
        )

        # å¦‚æœä½ æœ‰ scheduler æ¨¡å—å°±ç”¨ï¼Œæ²¡æœ‰å°±ç”¨æ ‡å‡†çš„
        try:
            scheduler = CosineAnnealingWithWarmupLR(
                optimizer,
                T_max=self.hparams.T_max,
                T_warmup=self.hparams.T_warmup,
                eta_min=1e-6
            )
            return [optimizer], [scheduler]
        except:
            return optimizer


# =================================================================
# 4. ä¸»ç¨‹åº
# =================================================================

def parse_args():
    parser = argparse.ArgumentParser(description="Q-PreNet Training")

    # è·¯å¾„é…ç½®
    parser.add_argument('--train_data_path', type=str, default=f'../../data/data_g3_z/train_dataset')
    parser.add_argument('--test_data_path', type=str, default=f'../../data/data_g3_z/test_dataset')
    parser.add_argument('--output_dir', type=str, default=f'{ROOT_PATH}/outputs/q_prenet')

    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--batch_size', type=int, default=64)
    parser.add_argument('--max_epochs', type=int, default=50)

    # Wandb
    parser.add_argument('--wandb_name', type=str, default=None)
    parser.add_argument('--wandb_offline', action='store_true')

    return parser.parse_args()


def main():
    args = parse_args()

    # 1. å®éªŒå‘½åä¸è·¯å¾„
    current_time = datetime.now().strftime("%m%d_%H%M")
    run_name = args.wandb_name if args.wandb_name else f"qprenet_sdss_15dim_{current_time}"
    experiment_dir = os.path.join(args.output_dir, run_name)
    os.makedirs(experiment_dir, exist_ok=True)

    print(f"ğŸš€ Starting Experiment: {run_name}")
    print(f"ğŸ“‚ Output Dir: {experiment_dir}")

    # 2. åŠ è½½æ•°æ®
    train_data = load_from_disk(args.train_data_path)
    test_data = load_from_disk(args.test_data_path)

    # åˆå§‹åŒ– Dataset: è¿™é‡Œçš„å…³é”®æ˜¯æŠŠå˜æ¢å‚æ•°å…¨è®¾ä¸º None/Falseï¼Œç›´æ¥ç”¨åŸå§‹æ•°æ®
    train_dataset = PairDataset(train_data, transform=None, extinction=False, probsTrans=False)
    test_dataset = PairDataset(test_data, transform=None, extinction=False, probsTrans=False)

    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)

    # 3. åˆå§‹åŒ–æ¨¡å‹
    model = QPreNet(lr=args.lr, weight_decay=1e-4)

    # 4. Logger é…ç½®
    wandb_logger = WandbLogger(
        project="astro-qprenet",
        name=run_name,
        save_dir=experiment_dir,
        offline=args.wandb_offline,
        log_model=True,
        version=run_name
    )

    # 5. Trainer é…ç½®
    # ä½ å¯ä»¥æ ¹æ® val_acc_0.15 æ¥ä¿å­˜æœ€ä½³æ¨¡å‹
    checkpoint_callback = pl.callbacks.ModelCheckpoint(
        dirpath=os.path.join(experiment_dir, "checkpoints"),
        monitor="val_acc_0.15",  # æ”¹ä¸ºç›‘æ§ 0.15 å‡†ç¡®ç‡
        save_top_k=2,
        mode="max",  # å‡†ç¡®ç‡è¶Šé«˜è¶Šå¥½
        filename='epoch_{epoch:03d}-acc015_{val_acc_0.15:.4f}',
        save_last=True
    )

    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')

    trainer = pl.Trainer(
        default_root_dir=experiment_dir,
        max_epochs=args.max_epochs,
        accelerator="gpu",
        devices=[4, 5, 6],  # ä½ çš„GPUè®¾ç½®
        strategy="ddp",
        logger=wandb_logger,
        callbacks=[checkpoint_callback, lr_monitor],
        gradient_clip_val=1.0
    )

    # 6. å¼€å§‹è®­ç»ƒ
    trainer.fit(model, train_loader, test_loader)
    wandb.finish()


if __name__ == '__main__':
    main()